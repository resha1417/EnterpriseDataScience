{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One run full walktrhough\n",
    "<ul>\n",
    "    <li>The full walk through on 100 countries</li>\n",
    "    <li>Dashboard for Covid_19 data for 100 countries</li>\n",
    "    <li>Understanding of the graphs</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: ads_covid_19'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some parameters\n",
    "## depending where you launch your notebook, the relative path might not work\n",
    "## you should start the notebook server from your base path\n",
    "## when opening the notebook, typically your path will be ../ads_covid-19/notebooks\n",
    "import os\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Update all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b'From https://github.com/CSSEGISandData/COVID-19\\n   392344be..fa91dd6d  web-data   -> origin/web-data\\n'\n",
      "out : b'Already up to date.\\n'\n",
      " Number of regions rows: 412\n"
     ]
    }
   ],
   "source": [
    "# %load src/data/get_data.py\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins_data():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( 'data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "def get_current_data_germany():\n",
    "    ''' Get current data from germany, attention API endpoint not too stable\n",
    "        Result data frame is stored as pd.DataFrame\n",
    "\n",
    "    '''\n",
    "    # 16 states\n",
    "    #data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    # 400 regions / Landkreise\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('/home/resha/ads_covid_19/data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins_data()\n",
    "    get_current_data_germany()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Process pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 63042\n",
      " Latest date is: 2020-09-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %load src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_johns_hopkins_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "    '''Static so we can drop it'''\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "    '''construct primary key with date and country'''\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "    '''date is string object type convert it into date type object'''\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_johns_hopkins_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "            date state  country  confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "34360 2020-09-10    no  Germany   258149.0            258018.2    160.722431   \n",
      "34361 2020-09-11    no  Germany   259735.0            259374.2    156.332930   \n",
      "34362 2020-09-12    no  Germany   260817.0            260732.0    194.577961   \n",
      "34363 2020-09-13    no  Germany   261737.0            261946.8    260.502498   \n",
      "34364 2020-09-14    no  Germany   263222.0            263161.6    217.817325   \n",
      "\n",
      "       confirmed_filtered_DR  \n",
      "34360             168.789051  \n",
      "34361             184.661656  \n",
      "34362             191.152480  \n",
      "34363             202.662158  \n",
      "34364             215.629569  \n"
     ]
    }
   ],
   "source": [
    "# %load src/features/build_features.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "    '''first we did it for 3 datapoints and we moved initial sata point to -1,0,1. Means x only approximate about -1,0 and 1.\n",
    "    we want to move target vector as close as possible to the inner triangle of a derivative to calculate slop.'''\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_JH_data=pd.read_csv('data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    #test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "    #                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_larg[pd_result_larg['country']=='Germany'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd_result_larg[pd_result_larg['country']=='US'].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed_filtered</th>\n",
       "      <th>confirmed_DR</th>\n",
       "      <th>confirmed_filtered_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>no</td>\n",
       "      <td>Korea, South</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>no</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>no</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>no</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63037</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>no</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>183.0</td>\n",
       "      <td>182.2</td>\n",
       "      <td>120.888889</td>\n",
       "      <td>259.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63038</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>no</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>74360.0</td>\n",
       "      <td>74362.0</td>\n",
       "      <td>385.295238</td>\n",
       "      <td>384.895174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63039</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>no</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>94306.0</td>\n",
       "      <td>94347.6</td>\n",
       "      <td>102.202407</td>\n",
       "      <td>99.433894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63040</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>no</td>\n",
       "      <td>Albania</td>\n",
       "      <td>11520.0</td>\n",
       "      <td>11518.2</td>\n",
       "      <td>67.777114</td>\n",
       "      <td>68.722760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63041</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>no</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>7540.0</td>\n",
       "      <td>654.057971</td>\n",
       "      <td>370.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63042 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    state       country  confirmed  confirmed_filtered  \\\n",
       "0      2020-01-22  Alberta        Canada        0.0                 0.0   \n",
       "1      2020-01-22       no  Korea, South        1.0                 0.8   \n",
       "2      2020-01-22       no        Kosovo        0.0                 0.0   \n",
       "3      2020-01-22       no        Kuwait        0.0                 0.0   \n",
       "4      2020-01-22       no    Kyrgyzstan        0.0                 0.0   \n",
       "...           ...      ...           ...        ...                 ...   \n",
       "63037  2020-09-14       no      Barbados      183.0               182.2   \n",
       "63038  2020-09-14       no       Belarus    74360.0             74362.0   \n",
       "63039  2020-09-14       no       Belgium    94306.0             94347.6   \n",
       "63040  2020-09-14       no       Albania    11520.0             11518.2   \n",
       "63041  2020-09-14       no      Zimbabwe     7531.0              7540.0   \n",
       "\n",
       "       confirmed_DR  confirmed_filtered_DR  \n",
       "0               NaN                    NaN  \n",
       "1               NaN                    NaN  \n",
       "2               NaN                    NaN  \n",
       "3               NaN                    NaN  \n",
       "4               NaN                    NaN  \n",
       "...             ...                    ...  \n",
       "63037    120.888889             259.285714  \n",
       "63038    385.295238             384.895174  \n",
       "63039    102.202407              99.433894  \n",
       "63040     67.777114              68.722760  \n",
       "63041    654.057971             370.428571  \n",
       "\n",
       "[63042 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_large=pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "df_input_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed_filtered</th>\n",
       "      <th>confirmed_DR</th>\n",
       "      <th>confirmed_filtered_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61753</th>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>258149.0</td>\n",
       "      <td>258018.2</td>\n",
       "      <td>160.722431</td>\n",
       "      <td>168.789051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62021</th>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>259735.0</td>\n",
       "      <td>259374.2</td>\n",
       "      <td>156.332930</td>\n",
       "      <td>184.661656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62285</th>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>260817.0</td>\n",
       "      <td>260732.0</td>\n",
       "      <td>194.577961</td>\n",
       "      <td>191.152480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62553</th>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>261737.0</td>\n",
       "      <td>261946.8</td>\n",
       "      <td>260.502498</td>\n",
       "      <td>202.662158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62818</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>no</td>\n",
       "      <td>Germany</td>\n",
       "      <td>263222.0</td>\n",
       "      <td>263161.6</td>\n",
       "      <td>217.817325</td>\n",
       "      <td>215.629569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date state  country  confirmed  confirmed_filtered  confirmed_DR  \\\n",
       "43     2020-01-22    no  Germany        0.0                 0.0           NaN   \n",
       "308    2020-01-23    no  Germany        0.0                 0.0           NaN   \n",
       "575    2020-01-24    no  Germany        0.0                 0.0           NaN   \n",
       "841    2020-01-25    no  Germany        0.0                 0.2           NaN   \n",
       "1107   2020-01-26    no  Germany        0.0                 1.0           NaN   \n",
       "...           ...   ...      ...        ...                 ...           ...   \n",
       "61753  2020-09-10    no  Germany   258149.0            258018.2    160.722431   \n",
       "62021  2020-09-11    no  Germany   259735.0            259374.2    156.332930   \n",
       "62285  2020-09-12    no  Germany   260817.0            260732.0    194.577961   \n",
       "62553  2020-09-13    no  Germany   261737.0            261946.8    260.502498   \n",
       "62818  2020-09-14    no  Germany   263222.0            263161.6    217.817325   \n",
       "\n",
       "       confirmed_filtered_DR  \n",
       "43                       NaN  \n",
       "308                      NaN  \n",
       "575                      NaN  \n",
       "841                      NaN  \n",
       "1107                     NaN  \n",
       "...                      ...  \n",
       "61753             168.789051  \n",
       "62021             184.661656  \n",
       "62285             191.152480  \n",
       "62553             202.662158  \n",
       "62818             215.629569  \n",
       "\n",
       "[237 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot=df_input_large[df_input_large['country']=='Germany']\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed_filtered</th>\n",
       "      <th>confirmed_DR</th>\n",
       "      <th>confirmed_filtered_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>258149.0</td>\n",
       "      <td>258018.2</td>\n",
       "      <td>160.722431</td>\n",
       "      <td>168.789051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>259735.0</td>\n",
       "      <td>259374.2</td>\n",
       "      <td>156.332930</td>\n",
       "      <td>184.661656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>260817.0</td>\n",
       "      <td>260732.0</td>\n",
       "      <td>194.577961</td>\n",
       "      <td>191.152480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>261737.0</td>\n",
       "      <td>261946.8</td>\n",
       "      <td>260.502498</td>\n",
       "      <td>202.662158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>263222.0</td>\n",
       "      <td>263161.6</td>\n",
       "      <td>217.817325</td>\n",
       "      <td>215.629569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country        date  confirmed  confirmed_filtered  confirmed_DR  \\\n",
       "0    Germany  2020-01-22        0.0                 0.0           NaN   \n",
       "1    Germany  2020-01-23        0.0                 0.0           NaN   \n",
       "2    Germany  2020-01-24        0.0                 0.0           NaN   \n",
       "3    Germany  2020-01-25        0.0                 0.2           NaN   \n",
       "4    Germany  2020-01-26        0.0                 1.0           NaN   \n",
       "..       ...         ...        ...                 ...           ...   \n",
       "232  Germany  2020-09-10   258149.0            258018.2    160.722431   \n",
       "233  Germany  2020-09-11   259735.0            259374.2    156.332930   \n",
       "234  Germany  2020-09-12   260817.0            260732.0    194.577961   \n",
       "235  Germany  2020-09-13   261737.0            261946.8    260.502498   \n",
       "236  Germany  2020-09-14   263222.0            263161.6    217.817325   \n",
       "\n",
       "     confirmed_filtered_DR  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "..                     ...  \n",
       "232             168.789051  \n",
       "233             184.661656  \n",
       "234             191.152480  \n",
       "235             202.662158  \n",
       "236             215.629569  \n",
       "\n",
       "[237 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "# df_plot['doubling_rate_filtered']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dashboard for 100 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/resha/ads_covid_19\n",
      "Running on http://127.0.0.1:8050/\n",
      "Debugger PIN: 764-420-610\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "df_death=pd.read_csv('data/processed/COVID_death.csv',sep=';')\n",
    "df_death['date'] = pd.to_datetime(df_death['date'])\n",
    "df_recover=pd.read_csv('data/processed/COVID_recover.csv',sep=';')\n",
    "df_recover['date'] = pd.to_datetime(df_recover['date'])\n",
    "\n",
    "fig = go.Figure()\n",
    "'''generation of figure object, where everything is kept together'''\n",
    "\n",
    "app = dash.Dash()\n",
    "'''To visualize'''\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "\n",
    "    Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "    it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()[:100]],\n",
    "        value=['US', 'Germany','Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "   \n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "    \n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "   # print(country_list)\n",
    "    for each in country_list:\n",
    "#         print(each)\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "#         print(show_doubling)\n",
    "        #print(df_plot.head())\n",
    "\n",
    "        '''How to represent a data'''\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        )\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
